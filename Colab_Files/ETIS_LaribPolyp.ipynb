{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DMW_Project_ETIS_LaribPolyp.ipynb","provenance":[{"file_id":"1IqcgzUDEJRF5Amvj9GgUq7SLZe7-csDE","timestamp":1618131031163},{"file_id":"1rGUNJbv9wBX-DdUHQD948CsCq8-7a6G-","timestamp":1615123274867},{"file_id":"1SjT2NihknwXTljSuxPIjwmp-KD5vcjck","timestamp":1614861074566}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"h-f3b6hBsAWL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618145925738,"user_tz":-330,"elapsed":41332,"user":{"displayName":"RAJAT SHARMA","photoUrl":"","userId":"13976417869986616281"}},"outputId":"91c39e39-63ce-4bf7-ad35-21a0697d6381"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dc6go260sQDA"},"source":["import os\n","import random\n","import numpy as np\n","import cv2\n","from tqdm import tqdm\n","from glob import glob\n","import tifffile as tif\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.losses import binary_crossentropy\n","import json\n","from sklearn.utils import shuffle\n","from tensorflow.keras.utils import CustomObjectScope\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.applications import *\n","from tensorflow.keras.models import Model\n","\n","from albumentations import HorizontalFlip, VerticalFlip, CenterCrop, Crop, Transpose, ChannelShuffle\n","from tensorflow.keras.callbacks import *\n","from tensorflow.keras.optimizers import Adam, Nadam\n","from tensorflow.keras.metrics import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4hEdv-lktjWH"},"source":["smooth = 1e-15\n","\n","def dice_coef(y_true, y_pred):\n","    y_true = tf.keras.layers.Flatten()(y_true)\n","    y_pred = tf.keras.layers.Flatten()(y_pred)\n","    intersection = tf.reduce_sum(y_true * y_pred)\n","    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n","\n","def dice_loss(y_true, y_pred):\n","    return 1.0 - dice_coef(y_true, y_pred)\n","\n","def iou(y_true, y_pred):\n","    def f(y_true, y_pred):\n","        intersection = (y_true * y_pred).sum()\n","        union = y_true.sum() + y_pred.sum() - intersection\n","        x = (intersection + smooth) / (union + smooth)\n","        x = x.astype(np.float32)\n","        return x\n","    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n","\n","def bce_dice_loss(y_true, y_pred):\n","    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n","\n","def focal_loss(y_true, y_pred):\n","    alpha=0.25\n","    gamma=2\n","    def focal_loss_with_logits(logits, targets, alpha, gamma, y_pred):\n","        weight_a = alpha * (1 - y_pred) ** gamma * targets\n","        weight_b = (1 - alpha) * y_pred ** gamma * (1 - targets)\n","        return (tf.math.log1p(tf.exp(-tf.abs(logits))) + tf.nn.relu(-logits)) * (weight_a + weight_b) + logits * weight_b\n","\n","    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n","    logits = tf.math.log(y_pred / (1 - y_pred))\n","    loss = focal_loss_with_logits(logits=logits, targets=y_true, alpha=alpha, gamma=gamma, y_pred=y_pred)\n","    return tf.reduce_mean(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KUqPm3NxwNLH"},"source":["def squeeze_excite_block(inputs, ratio=8):\n","    init = inputs\n","    channel_axis = -1\n","    filters = init.shape[channel_axis]\n","    se_shape = (1, 1, filters)\n","\n","    se = GlobalAveragePooling2D()(init)\n","    se = Reshape(se_shape)(se)\n","    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n","    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n","\n","    x = Multiply()([init, se])\n","    return x\n","\n","def conv_block(inputs, filters):\n","    x = inputs\n","\n","    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = squeeze_excite_block(x)\n","\n","    return x\n","\n","def encoder1(inputs):\n","    skip_connections = []\n","\n","    model = VGG19(include_top=False, weights='imagenet', input_tensor=inputs)\n","    names = [\"block1_conv2\", \"block2_conv2\", \"block3_conv4\", \"block4_conv4\"]\n","    for name in names:\n","        skip_connections.append(model.get_layer(name).output)\n","\n","    output = model.get_layer(\"block5_conv4\").output\n","    return output, skip_connections\n","\n","def decoder1(inputs, skip_connections):\n","    num_filters = [256, 128, 64, 32]\n","    skip_connections.reverse()\n","    x = inputs\n","\n","    for i, f in enumerate(num_filters):\n","        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n","        x = Concatenate()([x, skip_connections[i]])\n","        x = conv_block(x, f)\n","\n","    return x\n","\n","def encoder2(inputs):\n","    num_filters = [32, 64, 128, 256]\n","    skip_connections = []\n","    x = inputs\n","\n","    for i, f in enumerate(num_filters):\n","        x = conv_block(x, f)\n","        skip_connections.append(x)\n","        x = MaxPool2D((2, 2))(x)\n","\n","    return x, skip_connections\n","\n","def decoder2(inputs, skip_1, skip_2):\n","    num_filters = [256, 128, 64, 32]\n","    skip_2.reverse()\n","    x = inputs\n","\n","    for i, f in enumerate(num_filters):\n","        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n","        x = Concatenate()([x, skip_1[i], skip_2[i]])\n","        x = conv_block(x, f)\n","\n","    return x\n","\n","def output_block(inputs):\n","    x = Conv2D(1, (1, 1), padding=\"same\")(inputs)\n","    x = Activation('sigmoid')(x)\n","    return x\n","\n","def Upsample(tensor, size):\n","    def _upsample(x, size):\n","        return tf.image.resize(images=x, size=size)\n","    return Lambda(lambda x: _upsample(x, size), output_shape=size)(tensor)\n","\n","def ASPP(x, filter):\n","    shape = x.shape\n","\n","    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n","    y1 = Conv2D(filter, 1, padding=\"same\")(y1)\n","    y1 = BatchNormalization()(y1)\n","    y1 = Activation(\"relu\")(y1)\n","    y1 = UpSampling2D((shape[1], shape[2]), interpolation='bilinear')(y1)\n","\n","    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(x)\n","    y2 = BatchNormalization()(y2)\n","    y2 = Activation(\"relu\")(y2)\n","\n","    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False)(x)\n","    y3 = BatchNormalization()(y3)\n","    y3 = Activation(\"relu\")(y3)\n","\n","    y4 = Conv2D(filter, 3, dilation_rate=12, padding=\"same\", use_bias=False)(x)\n","    y4 = BatchNormalization()(y4)\n","    y4 = Activation(\"relu\")(y4)\n","\n","    y5 = Conv2D(filter, 3, dilation_rate=18, padding=\"same\", use_bias=False)(x)\n","    y5 = BatchNormalization()(y5)\n","    y5 = Activation(\"relu\")(y5)\n","\n","    y = Concatenate()([y1, y2, y3, y4, y5])\n","\n","    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(y)\n","    y = BatchNormalization()(y)\n","    y = Activation(\"relu\")(y)\n","\n","    return y\n","\n","def build_model(shape):\n","    inputs = Input(shape)\n","    x, skip_1 = encoder1(inputs)\n","    x = ASPP(x, 64)\n","    x = decoder1(x, skip_1)\n","    outputs1 = output_block(x)\n","\n","    x = inputs * outputs1\n","\n","    x, skip_2 = encoder2(x)\n","    x = ASPP(x, 64)\n","    x = decoder2(x, skip_1, skip_2)\n","    outputs2 = output_block(x)\n","    outputs = Concatenate()([outputs1, outputs2])\n","\n","    model = Model(inputs, outputs)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VsBs6BwJxIXE"},"source":["def create_dir(path):\n","    try:\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","    except OSError:\n","        print(f\"Error: creating directory with name {path}\")\n","\n","def read_data(x, y):\n","    image = cv2.imread(x, cv2.IMREAD_COLOR)\n","    mask = cv2.imread(y, cv2.IMREAD_COLOR)\n","    return image, mask\n","\n","def read_params():\n","    with open(\"params.json\", \"r\") as f:\n","        data = f.read()\n","        params = json.loads(data)\n","        return params\n","\n","def load_data(path):\n","    images_path = os.path.join(path, \"image/*\")\n","    masks_path  = os.path.join(path, \"mask/*\")\n","\n","    images = glob(images_path)\n","    masks  = glob(masks_path)\n","\n","    return images, masks\n","\n","def shuffling(x, y):\n","    x, y = shuffle(x, y, random_state=42)\n","    return x, y\n","\n","def load_model_weight(path):\n","    with CustomObjectScope({'dice_loss': dice_loss, 'dice_coef': dice_coef, 'bce_dice_loss': bce_dice_loss, 'focal_loss': focal_loss, 'iou': iou}):\n","        model = load_model(path)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Btpq8_t-0oHy"},"source":["def augment_data(images, masks, save_path, augment=True):\n","    crop_size = (192-32, 256-32)\n","    size = (256, 192)\n","\n","    for image, mask in tqdm(zip(images, masks), total=len(images)):\n","        image_name = image.split(\"/\")[-1].split(\".\")[0]\n","        mask_name = mask.split(\"/\")[-1].split(\".\")[0]\n","\n","        x, y = read_data(image, mask)\n","        try:\n","            h, w, c = x.shape\n","        except Exception as e:\n","            image = image[:-1]\n","            x, y = read_data(image, mask)\n","            h, w, c = x.shape\n","\n","        if augment == True:\n","            ## Transpose\n","            aug = Transpose(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x4 = augmented['image']\n","            y4 = augmented['mask']\n","\n","            ## Channel Shuffle\n","            aug = ChannelShuffle(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x24 = augmented['image']\n","            y24 = augmented['mask']\n","\n","            images = [ x, x4, x24 ]\n","            masks  = [ y, y4, y24 ]\n","\n","        else:\n","            images = [x]\n","            masks  = [y]\n","\n","        idx = 0\n","        for i, m in zip(images, masks):\n","            i = cv2.resize(i, size)\n","            m = cv2.resize(m, size)\n","\n","            tmp_image_name = f\"{image_name}_{idx}.jpg\"\n","            tmp_mask_name  = f\"{mask_name}_{idx}.jpg\"\n","\n","            image_path = os.path.join(save_path, \"image/\", tmp_image_name)\n","            mask_path  = os.path.join(save_path, \"mask/\", tmp_mask_name)\n","\n","            cv2.imwrite(image_path, i)\n","            cv2.imwrite(mask_path, m)\n","\n","            idx += 1\n","\n","def load_data(path, split=0.1):\n","    img_path = glob(os.path.join(path, \"testx/*\"))\n","    msk_path = glob(os.path.join(path, \"testy/*\"))\n","\n","    img_path.sort()\n","    msk_path.sort()\n","\n","    len_ids = len(img_path)\n","    train_size = int((55/100)*len_ids)\n","    valid_size = int((15/100)*len_ids)\n","    test_size = int((30/100)*len_ids)\n","\n","    train_x, test_x = train_test_split(img_path, test_size=test_size, random_state=42)\n","    train_y, test_y = train_test_split(msk_path, test_size=test_size, random_state=42)\n","\n","    train_x, valid_x = train_test_split(train_x, test_size=valid_size, random_state=42)\n","    train_y, valid_y = train_test_split(train_y, test_size=valid_size, random_state=42)\n","\n","    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VqmZZesT5Ofh","executionInfo":{"status":"ok","timestamp":1618146777806,"user_tz":-330,"elapsed":647204,"user":{"displayName":"RAJAT SHARMA","photoUrl":"","userId":"13976417869986616281"}},"outputId":"e870f7f5-0cfb-4585-fd0c-d0ed3a19d794"},"source":["np.random.seed(42)\n","path = \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/ETIS_LaribPolypDB\"\n","(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(path, split=0.1)\n","\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/new_data/train/image/\")\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/new_data/train/mask/\")\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/new_data/valid/image/\")\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/new_data/valid/mask/\")\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/new_data/test/image/\")\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/new_data/test/mask/\")\n","\n","augment_data(train_x, train_y, \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/new_data/train/\", augment=True)\n","augment_data(valid_x, valid_y, \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/new_data/valid/\", augment=False)\n","augment_data(test_x, test_y, \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/new_data/test/\", augment=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 109/109 [06:07<00:00,  3.37s/it]\n","100%|██████████| 29/29 [01:38<00:00,  3.40s/it]\n","100%|██████████| 58/58 [02:54<00:00,  3.01s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"E16wVXqP9px9"},"source":["def read_image(x):\n","    x = x.decode()\n","    image = cv2.imread(x, cv2.IMREAD_COLOR)\n","    image = np.clip(image - np.median(image)+127, 0, 255)\n","    image = image/255.0\n","    image = image.astype(np.float32)\n","    return image\n","\n","def read_mask(y):\n","    y = y.decode()\n","    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n","    mask = mask/255.0\n","    mask = mask.astype(np.float32)\n","    mask = np.expand_dims(mask, axis=-1)\n","    return mask\n","\n","def parse_data(x, y):\n","    def _parse(x, y):\n","        x = read_image(x)\n","        y = read_mask(y)\n","        y = np.concatenate([y, y], axis=-1)\n","        return x, y\n","\n","    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n","    x.set_shape([192, 256, 3])\n","    y.set_shape([192, 256, 2])\n","    return x, y\n","\n","def tf_dataset(x, y, batch=8):\n","    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n","    dataset = dataset.shuffle(buffer_size=32)\n","    dataset = dataset.map(map_func=parse_data)\n","    dataset = dataset.repeat()\n","    dataset = dataset.batch(batch)\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TrqCR6d79udr","executionInfo":{"status":"ok","timestamp":1618151892077,"user_tz":-330,"elapsed":1635398,"user":{"displayName":"RAJAT SHARMA","photoUrl":"","userId":"13976417869986616281"}},"outputId":"fa2d0e91-d454-4e1f-b4d5-24602424318e"},"source":["np.random.seed(42)\n","tf.random.set_seed(42)\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/files\")\n","\n","train_path = \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/new_data/train\"\n","valid_path = \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/new_data/valid\"\n","\n","train_x = sorted(glob(os.path.join(train_path, \"image\", \"*.jpg\")))\n","train_y = sorted(glob(os.path.join(train_path, \"mask\", \"*.jpg\")))\n","train_x, train_y = shuffling(train_x, train_y)\n","\n","valid_x = sorted(glob(os.path.join(valid_path, \"image\", \"*.jpg\")))\n","valid_y = sorted(glob(os.path.join(valid_path, \"mask\", \"*.jpg\")))\n","\n","model_path = \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/files/model.h5\"\n","batch_size = 13\n","epochs = 30\n","lr = 1e-5\n","shape = (192, 256, 3)\n","\n","model = build_model(shape)\n","metrics = [ \"acc\", iou, Recall(), Precision() ]\n","\n","train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n","valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n","\n","model.compile(loss=\"binary_crossentropy\", optimizer=Nadam(lr), metrics=metrics)\n","\n","callbacks = [ ModelCheckpoint(model_path), ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20), CSVLogger(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/files/data.csv\"), TensorBoard(), EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False) ]\n","train_steps = (len(train_x)//batch_size)\n","valid_steps = (len(valid_x)//batch_size)\n","\n","if len(train_x) % batch_size != 0:\n","    train_steps += 1\n","\n","if len(valid_x) % batch_size != 0:\n","    valid_steps += 1\n","\n","model.fit(train_dataset, epochs=epochs, validation_data=valid_dataset, steps_per_epoch=train_steps, validation_steps=valid_steps, callbacks=callbacks, shuffle=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","26/26 [==============================] - 78s 2s/step - loss: 0.7762 - acc: 0.8015 - iou: 0.0389 - recall_4: 0.6925 - precision_4: 0.0497 - val_loss: 0.5873 - val_acc: 0.0337 - val_iou: 0.0480 - val_recall_4: 0.2553 - val_precision_4: 0.0584\n","Epoch 2/30\n","26/26 [==============================] - 49s 2s/step - loss: 0.7507 - acc: 0.8314 - iou: 0.0377 - recall_4: 0.7074 - precision_4: 0.0504 - val_loss: 0.6286 - val_acc: 0.0786 - val_iou: 0.0465 - val_recall_4: 0.4363 - val_precision_4: 0.0545\n","Epoch 3/30\n","26/26 [==============================] - 49s 2s/step - loss: 0.7235 - acc: 0.8572 - iou: 0.0403 - recall_4: 0.6925 - precision_4: 0.0552 - val_loss: 0.6619 - val_acc: 0.1373 - val_iou: 0.0549 - val_recall_4: 0.4572 - val_precision_4: 0.0656\n","Epoch 4/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.6964 - acc: 0.8719 - iou: 0.0434 - recall_4: 0.6687 - precision_4: 0.0624 - val_loss: 0.6794 - val_acc: 0.2391 - val_iou: 0.0478 - val_recall_4: 0.4536 - val_precision_4: 0.0562\n","Epoch 5/30\n","26/26 [==============================] - 49s 2s/step - loss: 0.6675 - acc: 0.8598 - iou: 0.0448 - recall_4: 0.6242 - precision_4: 0.0695 - val_loss: 0.6817 - val_acc: 0.3813 - val_iou: 0.0489 - val_recall_4: 0.3964 - val_precision_4: 0.0594\n","Epoch 6/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.6405 - acc: 0.8457 - iou: 0.0468 - recall_4: 0.5602 - precision_4: 0.0803 - val_loss: 0.6727 - val_acc: 0.5096 - val_iou: 0.0455 - val_recall_4: 0.3138 - val_precision_4: 0.0564\n","Epoch 7/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.6136 - acc: 0.8143 - iou: 0.0466 - recall_4: 0.4869 - precision_4: 0.0878 - val_loss: 0.6605 - val_acc: 0.6023 - val_iou: 0.0464 - val_recall_4: 0.2599 - val_precision_4: 0.0572\n","Epoch 8/30\n","26/26 [==============================] - 49s 2s/step - loss: 0.5889 - acc: 0.7791 - iou: 0.0504 - recall_4: 0.4956 - precision_4: 0.1176 - val_loss: 0.6495 - val_acc: 0.6647 - val_iou: 0.0464 - val_recall_4: 0.3030 - val_precision_4: 0.0699\n","Epoch 9/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.5689 - acc: 0.7553 - iou: 0.0487 - recall_4: 0.4900 - precision_4: 0.1351 - val_loss: 0.6287 - val_acc: 0.6470 - val_iou: 0.0430 - val_recall_4: 0.2679 - val_precision_4: 0.0716\n","Epoch 10/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.5513 - acc: 0.7303 - iou: 0.0523 - recall_4: 0.5091 - precision_4: 0.1750 - val_loss: 0.6091 - val_acc: 0.6859 - val_iou: 0.0481 - val_recall_4: 0.2740 - val_precision_4: 0.0865\n","Epoch 11/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.5395 - acc: 0.7349 - iou: 0.0563 - recall_4: 0.5384 - precision_4: 0.2159 - val_loss: 0.5932 - val_acc: 0.6826 - val_iou: 0.0490 - val_recall_4: 0.2737 - val_precision_4: 0.0999\n","Epoch 12/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.5277 - acc: 0.7171 - iou: 0.0498 - recall_4: 0.5090 - precision_4: 0.2125 - val_loss: 0.5831 - val_acc: 0.6760 - val_iou: 0.0533 - val_recall_4: 0.2195 - val_precision_4: 0.1058\n","Epoch 13/30\n","26/26 [==============================] - 49s 2s/step - loss: 0.5130 - acc: 0.7270 - iou: 0.0524 - recall_4: 0.5056 - precision_4: 0.2724 - val_loss: 0.5664 - val_acc: 0.7424 - val_iou: 0.0482 - val_recall_4: 0.2459 - val_precision_4: 0.1249\n","Epoch 14/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.5023 - acc: 0.7333 - iou: 0.0546 - recall_4: 0.5454 - precision_4: 0.3367 - val_loss: 0.5320 - val_acc: 0.6817 - val_iou: 0.0453 - val_recall_4: 0.1237 - val_precision_4: 0.1119\n","Epoch 15/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4981 - acc: 0.7334 - iou: 0.0541 - recall_4: 0.4927 - precision_4: 0.3396 - val_loss: 0.5149 - val_acc: 0.6817 - val_iou: 0.0485 - val_recall_4: 0.0959 - val_precision_4: 0.1298\n","Epoch 16/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4873 - acc: 0.7365 - iou: 0.0554 - recall_4: 0.5396 - precision_4: 0.4134 - val_loss: 0.4882 - val_acc: 0.6443 - val_iou: 0.0571 - val_recall_4: 0.0982 - val_precision_4: 0.2242\n","Epoch 17/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4811 - acc: 0.7474 - iou: 0.0584 - recall_4: 0.5413 - precision_4: 0.4292 - val_loss: 0.4716 - val_acc: 0.7213 - val_iou: 0.0511 - val_recall_4: 0.1346 - val_precision_4: 0.2896\n","Epoch 18/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4731 - acc: 0.7503 - iou: 0.0610 - recall_4: 0.5159 - precision_4: 0.5056 - val_loss: 0.4687 - val_acc: 0.7530 - val_iou: 0.0717 - val_recall_4: 0.2452 - val_precision_4: 0.5014\n","Epoch 19/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4621 - acc: 0.7444 - iou: 0.0612 - recall_4: 0.5615 - precision_4: 0.5763 - val_loss: 0.4531 - val_acc: 0.7824 - val_iou: 0.0591 - val_recall_4: 0.2743 - val_precision_4: 0.5188\n","Epoch 20/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4597 - acc: 0.7524 - iou: 0.0638 - recall_4: 0.5557 - precision_4: 0.5826 - val_loss: 0.4518 - val_acc: 0.7965 - val_iou: 0.0590 - val_recall_4: 0.2207 - val_precision_4: 0.5173\n","Epoch 21/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4570 - acc: 0.7774 - iou: 0.0610 - recall_4: 0.5661 - precision_4: 0.5837 - val_loss: 0.4432 - val_acc: 0.8212 - val_iou: 0.0635 - val_recall_4: 0.1648 - val_precision_4: 0.5333\n","Epoch 22/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4475 - acc: 0.7695 - iou: 0.0656 - recall_4: 0.5528 - precision_4: 0.6638 - val_loss: 0.4235 - val_acc: 0.8310 - val_iou: 0.0607 - val_recall_4: 0.2025 - val_precision_4: 0.6573\n","Epoch 23/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4432 - acc: 0.7875 - iou: 0.0654 - recall_4: 0.5789 - precision_4: 0.6789 - val_loss: 0.4075 - val_acc: 0.7500 - val_iou: 0.0542 - val_recall_4: 0.1714 - val_precision_4: 0.6521\n","Epoch 24/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4400 - acc: 0.7746 - iou: 0.0653 - recall_4: 0.5643 - precision_4: 0.6952 - val_loss: 0.4091 - val_acc: 0.8282 - val_iou: 0.0588 - val_recall_4: 0.3767 - val_precision_4: 0.7311\n","Epoch 25/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4417 - acc: 0.7868 - iou: 0.0641 - recall_4: 0.5770 - precision_4: 0.5860 - val_loss: 0.4127 - val_acc: 0.8595 - val_iou: 0.0653 - val_recall_4: 0.3698 - val_precision_4: 0.5000\n","Epoch 26/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4374 - acc: 0.7793 - iou: 0.0599 - recall_4: 0.5455 - precision_4: 0.6166 - val_loss: 0.4105 - val_acc: 0.8697 - val_iou: 0.0702 - val_recall_4: 0.3559 - val_precision_4: 0.7972\n","Epoch 27/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4290 - acc: 0.7984 - iou: 0.0631 - recall_4: 0.5937 - precision_4: 0.7165 - val_loss: 0.4049 - val_acc: 0.8661 - val_iou: 0.0758 - val_recall_4: 0.3986 - val_precision_4: 0.8329\n","Epoch 28/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4262 - acc: 0.8058 - iou: 0.0662 - recall_4: 0.5961 - precision_4: 0.7376 - val_loss: 0.4030 - val_acc: 0.8573 - val_iou: 0.0838 - val_recall_4: 0.4172 - val_precision_4: 0.8563\n","Epoch 29/30\n","26/26 [==============================] - 48s 2s/step - loss: 0.4215 - acc: 0.8068 - iou: 0.0717 - recall_4: 0.6192 - precision_4: 0.7779 - val_loss: 0.3990 - val_acc: 0.8439 - val_iou: 0.0756 - val_recall_4: 0.4750 - val_precision_4: 0.8071\n","Epoch 30/30\n","26/26 [==============================] - 49s 2s/step - loss: 0.4268 - acc: 0.8013 - iou: 0.0735 - recall_4: 0.5717 - precision_4: 0.6687 - val_loss: 0.4049 - val_acc: 0.8264 - val_iou: 0.1091 - val_recall_4: 0.5761 - val_precision_4: 0.8498\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f4c094ed8d0>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"iC_T1X6rA-WK"},"source":["def read_image_(x):\n","    image = cv2.imread(x, cv2.IMREAD_COLOR)\n","    image = np.clip(image - np.median(image)+127, 0, 255)\n","    image = image/255.0\n","    image = image.astype(np.float32)\n","    image = np.expand_dims(image, axis=0)\n","    return image\n","\n","def read_mask_(y):\n","    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n","    mask = mask.astype(np.float32)\n","    mask = mask/255.0\n","    mask = np.expand_dims(mask, axis=-1)\n","    return mask\n","\n","def mask_to_3d(mask):\n","    mask = np.squeeze(mask)\n","    mask = [mask, mask, mask]\n","    mask = np.transpose(mask, (1, 2, 0))\n","    return mask\n","\n","def parse(y_pred):\n","    y_pred = np.expand_dims(y_pred, axis=-1)\n","    y_pred = y_pred[..., -1]\n","    y_pred = y_pred.astype(np.float32)\n","    y_pred = np.expand_dims(y_pred, axis=-1)\n","    return y_pred\n","\n","def evaluate_normal(model, x_data, y_data):\n","    THRESHOLD = 0.5\n","    total = []\n","    for i, (x, y) in tqdm(enumerate(zip(x_data, y_data)), total=len(x_data)):\n","        x = read_image_(x)\n","        y = read_mask_(y)\n","        _, h, w, _ = x.shape\n","\n","        y_pred1 = parse(model.predict(x)[0][..., -2])\n","        y_pred2 = parse(model.predict(x)[0][..., -1])\n","        \n","        line = np.ones((h, 10, 3)) * 255.0\n","        \n","        all_images = [ x[0] * 255.0, line, mask_to_3d(y) * 255.0, line, mask_to_3d(y_pred1) * 255.0, line, mask_to_3d(y_pred2) * 255.0 ]\n","        mask = np.concatenate(all_images, axis=1)\n","\n","        cv2.imwrite(f\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/files/Results/{i}.png\", mask)\n","\n","smooth = 1."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23bU6_c5-ZHG","executionInfo":{"status":"ok","timestamp":1618152075592,"user_tz":-330,"elapsed":79489,"user":{"displayName":"RAJAT SHARMA","photoUrl":"","userId":"13976417869986616281"}},"outputId":"fd79b223-f2fc-4104-f520-fd5e36ae74cd"},"source":["np.random.seed(42)\n","tf.random.set_seed(42)\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/files/Results\")\n","\n","batch_size = 4\n","\n","test_path = \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/new_data/test\"\n","test_x = sorted(glob(os.path.join(test_path, \"image\", \"*.jpg\")))\n","test_y = sorted(glob(os.path.join(test_path, \"mask\", \"*.jpg\")))\n","test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\n","\n","test_steps = (len(test_x)//batch_size)\n","if len(test_x) % batch_size != 0:\n","    test_steps += 1\n","\n","model = load_model_weight(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data4/aesthetic/files/model.h5\")\n","\n","lr = 1e-5\n","metrics = [ \"acc\", iou, Recall(), Precision() ]\n","model.compile(loss=\"binary_crossentropy\", optimizer=Nadam(lr), metrics=metrics)\n","\n","model.evaluate(test_dataset, steps=test_steps)\n","evaluate_normal(model, test_x, test_y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["15/15 [==============================] - 9s 343ms/step - loss: 0.4079 - acc: 0.8694 - iou: 0.0843 - recall_5: 0.4542 - precision_5: 0.8504\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 58/58 [00:20<00:00,  2.86it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Y5H9U3cX47yr"},"source":[""]},{"cell_type":"code","metadata":{"id":"QNYbOzQx-ZFU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SBnZVgc1-ZDD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nNOMQ2E-Taxe"},"source":[""],"execution_count":null,"outputs":[]}]}