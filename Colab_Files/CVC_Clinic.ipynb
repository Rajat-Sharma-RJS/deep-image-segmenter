{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DMW_Project_CVC_Clinic.ipynb","provenance":[{"file_id":"1rGUNJbv9wBX-DdUHQD948CsCq8-7a6G-","timestamp":1618087614399},{"file_id":"1SjT2NihknwXTljSuxPIjwmp-KD5vcjck","timestamp":1614861074566}],"collapsed_sections":[],"authorship_tag":"ABX9TyP+N1x0rHgJtN0dd7/Dvv7A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"h-f3b6hBsAWL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618089541109,"user_tz":-330,"elapsed":32409,"user":{"displayName":"RAJAT SHARMA","photoUrl":"","userId":"13976417869986616281"}},"outputId":"a7a6b08f-ed36-45dd-ecdf-e5ed3266b928"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_MJu_xdslmtW"},"source":["import os\n","import random\n","import numpy as np\n","import cv2\n","from tqdm import tqdm\n","from glob import glob\n","import tifffile as tif\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.losses import binary_crossentropy\n","import json\n","from sklearn.utils import shuffle\n","from tensorflow.keras.utils import CustomObjectScope\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.applications import *\n","from tensorflow.keras.models import Model\n","from albumentations import HorizontalFlip, VerticalFlip, CenterCrop, Crop, Compose, Transpose\n","from tensorflow.keras.callbacks import *\n","from tensorflow.keras.optimizers import Adam, Nadam\n","from tensorflow.keras.metrics import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4hEdv-lktjWH"},"source":["smooth = 1e-15\n","\n","def dice_coef(y_true, y_pred):\n","    y_true = tf.keras.layers.Flatten()(y_true)\n","    y_pred = tf.keras.layers.Flatten()(y_pred)\n","    intersection = tf.reduce_sum(y_true * y_pred)\n","    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n","\n","def dice_loss(y_true, y_pred):\n","    return 1.0 - dice_coef(y_true, y_pred)\n","\n","def iou(y_true, y_pred):\n","    def f(y_true, y_pred):\n","        intersection = (y_true * y_pred).sum()\n","        union = y_true.sum() + y_pred.sum() - intersection\n","        x = (intersection + smooth) / (union + smooth)\n","        x = x.astype(np.float32)\n","        return x\n","    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n","\n","def bce_dice_loss(y_true, y_pred):\n","    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n","\n","def focal_loss(y_true, y_pred):\n","    alpha=0.25\n","    gamma=2\n","    def focal_loss_with_logits(logits, targets, alpha, gamma, y_pred):\n","        weight_a = alpha * (1 - y_pred) ** gamma * targets\n","        weight_b = (1 - alpha) * y_pred ** gamma * (1 - targets)\n","        return (tf.math.log1p(tf.exp(-tf.abs(logits))) + tf.nn.relu(-logits)) * (weight_a + weight_b) + logits * weight_b\n","\n","    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n","    logits = tf.math.log(y_pred / (1 - y_pred))\n","    loss = focal_loss_with_logits(logits=logits, targets=y_true, alpha=alpha, gamma=gamma, y_pred=y_pred)\n","    return tf.reduce_mean(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KUqPm3NxwNLH"},"source":["def squeeze_excite_block(inputs, ratio=8):\n","    init = inputs\n","    channel_axis = -1\n","    filters = init.shape[channel_axis]\n","    se_shape = (1, 1, filters)\n","\n","    se = GlobalAveragePooling2D()(init)\n","    se = Reshape(se_shape)(se)\n","    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n","    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n","\n","    x = Multiply()([init, se])\n","    return x\n","\n","def conv_block(inputs, filters):\n","    x = inputs\n","\n","    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = squeeze_excite_block(x)\n","\n","    return x\n","\n","def encoder1(inputs):\n","    skip_connections = []\n","\n","    model = VGG19(include_top=False, weights='imagenet', input_tensor=inputs)\n","    names = [\"block1_conv2\", \"block2_conv2\", \"block3_conv4\", \"block4_conv4\"]\n","    for name in names:\n","        skip_connections.append(model.get_layer(name).output)\n","\n","    output = model.get_layer(\"block5_conv4\").output\n","    return output, skip_connections\n","\n","def decoder1(inputs, skip_connections):\n","    num_filters = [256, 128, 64, 32]\n","    skip_connections.reverse()\n","    x = inputs\n","\n","    for i, f in enumerate(num_filters):\n","        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n","        x = Concatenate()([x, skip_connections[i]])\n","        x = conv_block(x, f)\n","\n","    return x\n","\n","def encoder2(inputs):\n","    num_filters = [32, 64, 128, 256]\n","    skip_connections = []\n","    x = inputs\n","\n","    for i, f in enumerate(num_filters):\n","        x = conv_block(x, f)\n","        skip_connections.append(x)\n","        x = MaxPool2D((2, 2))(x)\n","\n","    return x, skip_connections\n","\n","def decoder2(inputs, skip_1, skip_2):\n","    num_filters = [256, 128, 64, 32]\n","    skip_2.reverse()\n","    x = inputs\n","\n","    for i, f in enumerate(num_filters):\n","        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n","        x = Concatenate()([x, skip_1[i], skip_2[i]])\n","        x = conv_block(x, f)\n","\n","    return x\n","\n","def output_block(inputs):\n","    x = Conv2D(1, (1, 1), padding=\"same\")(inputs)\n","    x = Activation('sigmoid')(x)\n","    return x\n","\n","def Upsample(tensor, size):\n","    def _upsample(x, size):\n","        return tf.image.resize(images=x, size=size)\n","    return Lambda(lambda x: _upsample(x, size), output_shape=size)(tensor)\n","\n","def ASPP(x, filter):\n","    shape = x.shape\n","\n","    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n","    y1 = Conv2D(filter, 1, padding=\"same\")(y1)\n","    y1 = BatchNormalization()(y1)\n","    y1 = Activation(\"relu\")(y1)\n","    y1 = UpSampling2D((shape[1], shape[2]), interpolation='bilinear')(y1)\n","\n","    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(x)\n","    y2 = BatchNormalization()(y2)\n","    y2 = Activation(\"relu\")(y2)\n","\n","    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False)(x)\n","    y3 = BatchNormalization()(y3)\n","    y3 = Activation(\"relu\")(y3)\n","\n","    y4 = Conv2D(filter, 3, dilation_rate=12, padding=\"same\", use_bias=False)(x)\n","    y4 = BatchNormalization()(y4)\n","    y4 = Activation(\"relu\")(y4)\n","\n","    y5 = Conv2D(filter, 3, dilation_rate=18, padding=\"same\", use_bias=False)(x)\n","    y5 = BatchNormalization()(y5)\n","    y5 = Activation(\"relu\")(y5)\n","\n","    y = Concatenate()([y1, y2, y3, y4, y5])\n","\n","    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(y)\n","    y = BatchNormalization()(y)\n","    y = Activation(\"relu\")(y)\n","\n","    return y\n","\n","def build_model(shape):\n","    inputs = Input(shape)\n","    x, skip_1 = encoder1(inputs)\n","    x = ASPP(x, 64)\n","    x = decoder1(x, skip_1)\n","    outputs1 = output_block(x)\n","\n","    x = inputs * outputs1\n","\n","    x, skip_2 = encoder2(x)\n","    x = ASPP(x, 64)\n","    x = decoder2(x, skip_1, skip_2)\n","    outputs2 = output_block(x)\n","    outputs = Concatenate()([outputs1, outputs2])\n","\n","    model = Model(inputs, outputs)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VsBs6BwJxIXE"},"source":["def create_dir(path):\n","    try:\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","    except OSError:\n","        print(f\"Error: creating directory with name {path}\")\n","\n","def read_data(x, y):\n","    image = cv2.imread(x, cv2.IMREAD_COLOR)\n","    mask = cv2.imread(y, cv2.IMREAD_COLOR)\n","    return image, mask\n","\n","def read_params():\n","    with open(\"params.json\", \"r\") as f:\n","        data = f.read()\n","        params = json.loads(data)\n","        return params\n","\n","def load_data(path):\n","    images_path = os.path.join(path, \"image/*\")\n","    masks_path  = os.path.join(path, \"mask/*\")\n","\n","    images = glob(images_path)\n","    masks  = glob(masks_path)\n","\n","    return images, masks\n","\n","def shuffling(x, y):\n","    x, y = shuffle(x, y, random_state=42)\n","    return x, y\n","\n","def load_model_weight(path):\n","    with CustomObjectScope({'dice_loss': dice_loss, 'dice_coef': dice_coef, 'bce_dice_loss': bce_dice_loss, 'focal_loss': focal_loss, 'iou': iou}):\n","        model = load_model(path)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Btpq8_t-0oHy"},"source":["def augment_data(images, masks, save_path, augment=True):\n","    crop_size = (192-32, 256-32)\n","    size = (256, 192)\n","\n","    for image, mask in tqdm(zip(images, masks), total=len(images)):\n","        image_name = image.split(\"/\")[-1].split(\".\")[0]\n","        mask_name = mask.split(\"/\")[-1].split(\".\")[0]\n","\n","        x, y = read_data(image, mask)\n","        try:\n","            h, w, c = x.shape\n","        except Exception as e:\n","            image = image[:-1]\n","            x, y = read_data(image, mask)\n","            h, w, c = x.shape\n","\n","        if augment == True:\n","            ## Transpose\n","            aug = Transpose(p=1)\n","            augmented = aug(image=x, mask=y)\n","            x4 = augmented['image']\n","            y4 = augmented['mask']\n","\n","            images = [ x, x4 ]\n","            masks  = [ y, y4 ]\n","\n","        else:\n","            images = [x]\n","            masks  = [y]\n","\n","        idx = 0\n","        for i, m in zip(images, masks):\n","            i = cv2.resize(i, size)\n","            m = cv2.resize(m, size)\n","\n","            tmp_image_name = f\"{image_name}_{idx}.jpg\"\n","            tmp_mask_name  = f\"{mask_name}_{idx}.jpg\"\n","\n","            image_path = os.path.join(save_path, \"image/\", tmp_image_name)\n","            mask_path  = os.path.join(save_path, \"mask/\", tmp_mask_name)\n","\n","            cv2.imwrite(image_path, i)\n","            cv2.imwrite(mask_path, m)\n","\n","            idx += 1\n","\n","def get_data(path, split=0.1):\n","    train_x = glob(os.path.join(path, \"trainx/*\"))\n","    train_y = glob(os.path.join(path, \"trainy/*\"))\n","\n","    valid_x = glob(os.path.join(path, \"validationx/*\"))\n","    valid_y = glob(os.path.join(path, \"validationy/*\"))\n","\n","    test_x = glob(os.path.join(path, \"testx/*\"))\n","    test_y = glob(os.path.join(path, \"testy/*\"))\n","\n","    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3hje0sqoAOm","executionInfo":{"status":"ok","timestamp":1618090722879,"user_tz":-330,"elapsed":732017,"user":{"displayName":"RAJAT SHARMA","photoUrl":"","userId":"13976417869986616281"}},"outputId":"999298f8-e9ab-4212-b713-d4f970c157f1"},"source":["np.random.seed(42)\n","path = \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/cvc_data\"\n","(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = get_data(path, split=0.1)\n","\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/new_data/train/image/\")\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/new_data/train/mask/\")\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/new_data/valid/image/\")\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/new_data/valid/mask/\")\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/new_data/test/image/\")\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/new_data/test/mask/\")\n","\n","augment_data(train_x, train_y, \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/new_data/train/\", augment=True)\n","augment_data(valid_x, valid_y, \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/new_data/valid/\", augment=False)\n","augment_data(test_x, test_y, \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/new_data/test/\", augment=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 366/366 [07:16<00:00,  1.19s/it]\n","100%|██████████| 123/123 [02:22<00:00,  1.16s/it]\n","100%|██████████| 123/123 [02:19<00:00,  1.13s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"E16wVXqP9px9"},"source":["def read_image(x):\n","    x = x.decode()\n","    image = cv2.imread(x, cv2.IMREAD_COLOR)\n","    image = np.clip(image - np.median(image)+127, 0, 255)\n","    image = image/255.0\n","    image = image.astype(np.float32)\n","    return image\n","\n","def read_mask(y):\n","    y = y.decode()\n","    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n","    mask = mask/255.0\n","    mask = mask.astype(np.float32)\n","    mask = np.expand_dims(mask, axis=-1)\n","    return mask\n","\n","def parse_data(x, y):\n","    def _parse(x, y):\n","        x = read_image(x)\n","        y = read_mask(y)\n","        y = np.concatenate([y, y], axis=-1)\n","        return x, y\n","\n","    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n","    x.set_shape([192, 256, 3])\n","    y.set_shape([192, 256, 2])\n","    return x, y\n","\n","def tf_dataset(x, y, batch=8):\n","    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n","    dataset = dataset.shuffle(buffer_size=32)\n","    dataset = dataset.map(map_func=parse_data)\n","    dataset = dataset.repeat()\n","    dataset = dataset.batch(batch)\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xE-pFOLjoJAx","executionInfo":{"status":"ok","timestamp":1618092252593,"user_tz":-330,"elapsed":1172222,"user":{"displayName":"RAJAT SHARMA","photoUrl":"","userId":"13976417869986616281"}},"outputId":"daaf959a-2df5-4ba7-84cc-0c1d7de7205b"},"source":["np.random.seed(42)\n","tf.random.set_seed(42)\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/files\")\n","\n","train_path = \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/new_data/train\"\n","valid_path = \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/new_data/valid\"\n","\n","## Training\n","train_x = sorted(glob(os.path.join(train_path, \"image\", \"*.jpg\")))\n","train_y = sorted(glob(os.path.join(train_path, \"mask\", \"*.jpg\")))\n","\n","## Shuffling\n","train_x, train_y = shuffling(train_x, train_y)\n","\n","## Validation\n","valid_x = sorted(glob(os.path.join(valid_path, \"image\", \"*.jpg\")))\n","valid_y = sorted(glob(os.path.join(valid_path, \"mask\", \"*.jpg\")))\n","\n","model_path = \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/files/model.h5\"\n","batch_size = 16\n","epochs = 20\n","lr = 1e-5\n","shape = (192, 256, 3)\n","\n","model = build_model(shape)\n","metrics = [ \"acc\", iou, Recall(), Precision() ]\n","\n","train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n","valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n","\n","model.compile(loss=\"binary_crossentropy\", optimizer=Nadam(lr), metrics=metrics)\n","\n","callbacks = [ ModelCheckpoint(model_path), ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20), CSVLogger(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/files/data.csv\"), TensorBoard(), EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False) ]\n","\n","train_steps = (len(train_x)//batch_size)\n","valid_steps = (len(valid_x)//batch_size)\n","\n","if len(train_x) % batch_size != 0:\n","    train_steps += 1\n","\n","if len(valid_x) % batch_size != 0:\n","    valid_steps += 1\n","\n","model.fit(train_dataset, epochs=epochs, validation_data=valid_dataset, steps_per_epoch=train_steps, validation_steps=valid_steps, callbacks=callbacks, shuffle=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80142336/80134624 [==============================] - 0s 0us/step\n","Epoch 1/20\n","46/46 [==============================] - 115s 1s/step - loss: 0.7460 - acc: 0.8031 - iou: 0.0927 - recall: 0.7682 - precision: 0.1329 - val_loss: 0.6970 - val_acc: 0.0759 - val_iou: 0.0917 - val_recall: 0.5708 - val_precision: 0.1213\n","Epoch 2/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.6789 - acc: 0.8348 - iou: 0.1015 - recall: 0.7989 - precision: 0.1685 - val_loss: 0.7188 - val_acc: 0.3121 - val_iou: 0.0939 - val_recall: 0.7827 - val_precision: 0.1165\n","Epoch 3/20\n","46/46 [==============================] - 50s 1s/step - loss: 0.6336 - acc: 0.8659 - iou: 0.1074 - recall: 0.7902 - precision: 0.1941 - val_loss: 0.7166 - val_acc: 0.5140 - val_iou: 0.0974 - val_recall: 0.9349 - val_precision: 0.1353\n","Epoch 4/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.5902 - acc: 0.8913 - iou: 0.1222 - recall: 0.7612 - precision: 0.2404 - val_loss: 0.7027 - val_acc: 0.6061 - val_iou: 0.0964 - val_recall: 0.9222 - val_precision: 0.1474\n","Epoch 5/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.5501 - acc: 0.8946 - iou: 0.1406 - recall: 0.7584 - precision: 0.3096 - val_loss: 0.6751 - val_acc: 0.7318 - val_iou: 0.1005 - val_recall: 0.8840 - val_precision: 0.1690\n","Epoch 6/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.5132 - acc: 0.8929 - iou: 0.1542 - recall: 0.7628 - precision: 0.4460 - val_loss: 0.6313 - val_acc: 0.9173 - val_iou: 0.1003 - val_recall: 0.6230 - val_precision: 0.1775\n","Epoch 7/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.4813 - acc: 0.8887 - iou: 0.1674 - recall: 0.7720 - precision: 0.5934 - val_loss: 0.5823 - val_acc: 0.9534 - val_iou: 0.0990 - val_recall: 0.3625 - val_precision: 0.1638\n","Epoch 8/20\n","46/46 [==============================] - 50s 1s/step - loss: 0.4581 - acc: 0.8771 - iou: 0.1764 - recall: 0.7812 - precision: 0.6915 - val_loss: 0.5580 - val_acc: 0.9628 - val_iou: 0.1023 - val_recall: 0.3350 - val_precision: 0.1809\n","Epoch 9/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.4373 - acc: 0.8643 - iou: 0.1863 - recall: 0.7857 - precision: 0.7692 - val_loss: 0.5287 - val_acc: 0.9603 - val_iou: 0.1227 - val_recall: 0.4368 - val_precision: 0.2493\n","Epoch 10/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.4200 - acc: 0.8572 - iou: 0.1955 - recall: 0.8057 - precision: 0.8216 - val_loss: 0.5050 - val_acc: 0.9586 - val_iou: 0.1306 - val_recall: 0.4354 - val_precision: 0.3176\n","Epoch 11/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.4061 - acc: 0.8652 - iou: 0.2033 - recall: 0.8088 - precision: 0.8587 - val_loss: 0.4776 - val_acc: 0.9473 - val_iou: 0.1411 - val_recall: 0.4777 - val_precision: 0.5305\n","Epoch 12/20\n","46/46 [==============================] - 50s 1s/step - loss: 0.3975 - acc: 0.8712 - iou: 0.2072 - recall: 0.8083 - precision: 0.8788 - val_loss: 0.4557 - val_acc: 0.9500 - val_iou: 0.1501 - val_recall: 0.4885 - val_precision: 0.7338\n","Epoch 13/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.3881 - acc: 0.8766 - iou: 0.2106 - recall: 0.8162 - precision: 0.9034 - val_loss: 0.4423 - val_acc: 0.9465 - val_iou: 0.1603 - val_recall: 0.5331 - val_precision: 0.7646\n","Epoch 14/20\n","46/46 [==============================] - 50s 1s/step - loss: 0.3812 - acc: 0.8868 - iou: 0.2131 - recall: 0.8212 - precision: 0.9164 - val_loss: 0.4252 - val_acc: 0.9446 - val_iou: 0.1611 - val_recall: 0.5226 - val_precision: 0.8048\n","Epoch 15/20\n","46/46 [==============================] - 50s 1s/step - loss: 0.3762 - acc: 0.8955 - iou: 0.2144 - recall: 0.8251 - precision: 0.9218 - val_loss: 0.4238 - val_acc: 0.9437 - val_iou: 0.1611 - val_recall: 0.5037 - val_precision: 0.7994\n","Epoch 16/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.3716 - acc: 0.8974 - iou: 0.2141 - recall: 0.8305 - precision: 0.9225 - val_loss: 0.4117 - val_acc: 0.9204 - val_iou: 0.1687 - val_recall: 0.5384 - val_precision: 0.8146\n","Epoch 17/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.3645 - acc: 0.9027 - iou: 0.2192 - recall: 0.8415 - precision: 0.9381 - val_loss: 0.4123 - val_acc: 0.9185 - val_iou: 0.1691 - val_recall: 0.5524 - val_precision: 0.7767\n","Epoch 18/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.3615 - acc: 0.9029 - iou: 0.2203 - recall: 0.8416 - precision: 0.9359 - val_loss: 0.4297 - val_acc: 0.9043 - val_iou: 0.1867 - val_recall: 0.6649 - val_precision: 0.7140\n","Epoch 19/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.3570 - acc: 0.9062 - iou: 0.2214 - recall: 0.8418 - precision: 0.9434 - val_loss: 0.4039 - val_acc: 0.9150 - val_iou: 0.1743 - val_recall: 0.5239 - val_precision: 0.8191\n","Epoch 20/20\n","46/46 [==============================] - 51s 1s/step - loss: 0.3518 - acc: 0.9115 - iou: 0.2288 - recall: 0.8470 - precision: 0.9493 - val_loss: 0.4125 - val_acc: 0.8747 - val_iou: 0.1804 - val_recall: 0.6191 - val_precision: 0.7482\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f30315cdfd0>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"iC_T1X6rA-WK"},"source":["def read_image_(x):\n","    image = cv2.imread(x, cv2.IMREAD_COLOR)\n","    image = np.clip(image - np.median(image)+127, 0, 255)\n","    image = image/255.0\n","    image = image.astype(np.float32)\n","    image = np.expand_dims(image, axis=0)\n","    return image\n","\n","def read_mask_(y):\n","    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n","    mask = mask.astype(np.float32)\n","    mask = mask/255.0\n","    mask = np.expand_dims(mask, axis=-1)\n","    return mask\n","\n","def mask_to_3d(mask):\n","    mask = np.squeeze(mask)\n","    mask = [mask, mask, mask]\n","    mask = np.transpose(mask, (1, 2, 0))\n","    return mask\n","\n","def parse(y_pred):\n","    y_pred = np.expand_dims(y_pred, axis=-1)\n","    y_pred = y_pred[..., -1]\n","    y_pred = y_pred.astype(np.float32)\n","    y_pred = np.expand_dims(y_pred, axis=-1)\n","    return y_pred\n","\n","def evaluate_normal(model, x_data, y_data):\n","    THRESHOLD = 0.5\n","    total = []\n","    for i, (x, y) in tqdm(enumerate(zip(x_data, y_data)), total=len(x_data)):\n","        x = read_image_(x)\n","        y = read_mask_(y)\n","        _, h, w, _ = x.shape\n","\n","        y_pred1 = parse(model.predict(x)[0][..., -2])\n","        y_pred2 = parse(model.predict(x)[0][..., -1])\n","        \n","        line = np.ones((h, 10, 3)) * 255.0\n","        \n","        all_images = [ x[0] * 255.0, line, mask_to_3d(y) * 255.0, line, mask_to_3d(y_pred1) * 255.0, line, mask_to_3d(y_pred2) * 255.0 ]\n","        mask = np.concatenate(all_images, axis=1)\n","\n","        cv2.imwrite(f\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/files/results/{i}.png\", mask)\n","\n","smooth = 1."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ko-rnauTaza","executionInfo":{"status":"ok","timestamp":1618092408436,"user_tz":-330,"elapsed":50881,"user":{"displayName":"RAJAT SHARMA","photoUrl":"","userId":"13976417869986616281"}},"outputId":"7f9e5119-6b68-4729-e0ee-bbd477c5d8f6"},"source":["np.random.seed(42)\n","tf.random.set_seed(42)\n","create_dir(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/files/results/\")\n","\n","batch_size = 8\n","\n","test_path = \"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/new_data/test\"\n","test_x = sorted(glob(os.path.join(test_path, \"image\", \"*.jpg\")))\n","test_y = sorted(glob(os.path.join(test_path, \"mask\", \"*.jpg\")))\n","test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\n","\n","test_steps = (len(test_x)//batch_size)\n","if len(test_x) % batch_size != 0:\n","    test_steps += 1\n","\n","model = load_model_weight(\"/content/drive/MyDrive/SEM6/DMW/DMW_Project/data2/aesthetic/files/model.h5\")\n","\n","lr = 1e-5\n","metrics = [ \"acc\", iou, Recall(), Precision() ]\n","model.compile(loss=\"binary_crossentropy\", optimizer=Nadam(lr), metrics=metrics)\n","\n","model.evaluate(test_dataset, steps=test_steps)\n","evaluate_normal(model, test_x, test_y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["16/16 [==============================] - 11s 242ms/step - loss: 0.4272 - acc: 0.8620 - iou: 0.2075 - recall_1: 0.6643 - precision_1: 0.7330\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 123/123 [00:25<00:00,  4.90it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"nNOMQ2E-Taxe"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZh1gYZxpUGH"},"source":[""],"execution_count":null,"outputs":[]}]}